{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5bd425a-dfc5-4560-a927-c42ac6e1160a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T09:28:42.333839Z",
     "iopub.status.busy": "2025-11-10T09:28:42.333599Z",
     "iopub.status.idle": "2025-11-10T09:28:43.302091Z",
     "shell.execute_reply": "2025-11-10T09:28:43.301079Z",
     "shell.execute_reply.started": "2025-11-10T09:28:42.333818Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# baseline_paddle.py\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99281557-385c-4c7f-bdc2-14ef4e9f450b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T09:28:43.303450Z",
     "iopub.status.busy": "2025-11-10T09:28:43.303177Z",
     "iopub.status.idle": "2025-11-10T09:28:43.306618Z",
     "shell.execute_reply": "2025-11-10T09:28:43.305784Z",
     "shell.execute_reply.started": "2025-11-10T09:28:43.303431Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ========== 配置 ==========\n",
    "NPZ_PATH = \"phase1_gdata.npz\"   # 请确保文件在当前目录\n",
    "OUTPUT_NPY = \"submission_baseline.npy\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a58723c-ff08-45d6-9455-9073f28334a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T09:28:43.489479Z",
     "iopub.status.busy": "2025-11-10T09:28:43.488591Z",
     "iopub.status.idle": "2025-11-10T09:28:52.772077Z",
     "shell.execute_reply": "2025-11-10T09:28:52.770394Z",
     "shell.execute_reply.started": "2025-11-10T09:28:43.489457Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading npz: phase1_gdata.npz\r\n",
      "Nodes = 4024623, Features = (4024623, 17), Edges = 4927620\r\n",
      "recent_feats: (4024623, 14)\r\n",
      "new_feats: (4024623, 10)\r\n",
      "more_feats: (4024623, 11)\r\n",
      "new_feats_all: (4024623, 21)\r\n",
      "struct_feats: (4024623, 39)\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# =====================================================\n",
    "# 1) 加载数据\n",
    "# =====================================================\n",
    "print(\"Loading npz:\", NPZ_PATH)\n",
    "data = np.load(NPZ_PATH, allow_pickle=True)\n",
    "\n",
    "x              = data[\"x\"].astype(np.float32)            # (N,17)\n",
    "y              = data[\"y\"].squeeze()                     # (N,)\n",
    "edge_index     = data[\"edge_index\"].astype(np.int64)     # (E,2)\n",
    "edge_type      = data[\"edge_type\"].squeeze()\n",
    "edge_timestamp = data[\"edge_timestamp\"].squeeze()\n",
    "train_mask     = data[\"train_mask\"].astype(np.int64)\n",
    "test_mask      = data[\"test_mask\"].astype(np.int64)\n",
    "\n",
    "N = x.shape[0]\n",
    "E = edge_index.shape[0]\n",
    "print(f\"Nodes = {N}, Features = {x.shape}, Edges = {E}\")\n",
    "\n",
    "# =====================================================\n",
    "# 2) 窗口特征 recent_feats\n",
    "# =====================================================\n",
    "max_day = int(edge_timestamp.max())\n",
    "\n",
    "win_base = np.array([3, 7, 14, 30, 60, 90, 180], dtype=np.int32)\n",
    "win_days = np.concatenate([win_base, max_day - win_base])\n",
    "win_threshold = max_day - win_days\n",
    "W = len(win_threshold)\n",
    "\n",
    "# edge mask (E,W)\n",
    "edge_ts = edge_timestamp.reshape(-1, 1)\n",
    "mask = edge_ts >= win_threshold.reshape(1, -1)   # True/False\n",
    "\n",
    "# flatten for in/out\n",
    "nodes_flat = np.concatenate([edge_index[:, 0], edge_index[:, 1]])\n",
    "mask_flat = np.concatenate([mask, mask], axis=0)\n",
    "\n",
    "recent_feats = np.zeros((N, W), dtype=np.float32)\n",
    "for w in range(W):\n",
    "    recent_feats[:, w] = np.bincount(\n",
    "        nodes_flat,\n",
    "        weights=mask_flat[:, w].astype(np.float32),\n",
    "        minlength=N\n",
    "    )\n",
    "\n",
    "print(\"recent_feats:\", recent_feats.shape)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3) 基础结构特征\n",
    "# =====================================================\n",
    "out_deg = np.bincount(edge_index[:, 0], minlength=N).astype(np.float32)\n",
    "in_deg  = np.bincount(edge_index[:, 1], minlength=N).astype(np.float32)\n",
    "deg     = in_deg + out_deg\n",
    "deg_diff = out_deg - in_deg\n",
    "\n",
    "# min / max day\n",
    "min_day = np.full(N,  1e9,  dtype=np.float32)\n",
    "max_day_node = np.full(N, -1e9, dtype=np.float32)\n",
    "\n",
    "ts_flat = np.concatenate([edge_timestamp, edge_timestamp])\n",
    "np.minimum.at(min_day, nodes_flat, ts_flat)\n",
    "np.maximum.at(max_day_node, nodes_flat, ts_flat)\n",
    "\n",
    "active_span = max_day_node - min_day\n",
    "active_span[active_span < 0] = 0\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 4) 时间统计\n",
    "# =====================================================\n",
    "day_sum = np.bincount(nodes_flat, weights=ts_flat, minlength=N)\n",
    "day_cnt = np.bincount(nodes_flat, minlength=N)\n",
    "day_mean = day_sum / np.maximum(day_cnt, 1)\n",
    "\n",
    "day_skew = (max_day_node - day_mean) / (active_span + 1e-6)\n",
    "\n",
    "deg_norm = deg / np.maximum(day_cnt, 1)\n",
    "\n",
    "Tmax = max_day_node.max() + 1e-6\n",
    "time_weight = ts_flat / Tmax\n",
    "\n",
    "w_out = np.zeros(N, dtype=np.float32)\n",
    "w_in  = np.zeros(N, dtype=np.float32)\n",
    "\n",
    "np.add.at(w_out, edge_index[:, 0], time_weight[:E])\n",
    "np.add.at(w_in,  edge_index[:, 1], time_weight[E:])\n",
    "time_weighted_deg = w_out + w_in\n",
    "\n",
    "# last_active_norm\n",
    "mmin = min_day.min()\n",
    "mmax = min_day.max() + 1e-6\n",
    "last_active_norm = (max_day_node - mmin) / (mmax - mmin)\n",
    "\n",
    "X_recent = 30\n",
    "global_max = max_day_node.max()\n",
    "recent_active = (max_day_node > global_max - X_recent).astype(np.float32)\n",
    "\n",
    "median_span = np.median(active_span)\n",
    "active_long = (active_span > median_span).astype(np.float32)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 5) new_feats\n",
    "# =====================================================\n",
    "new_feats = np.stack([\n",
    "    deg,\n",
    "    deg_diff,\n",
    "    active_span,\n",
    "    day_mean,\n",
    "    day_skew,\n",
    "    deg_norm,\n",
    "    time_weighted_deg,\n",
    "    last_active_norm,\n",
    "    active_long,\n",
    "    recent_active,\n",
    "], axis=1).astype(np.float32)\n",
    "print(\"new_feats:\", new_feats.shape)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 6) more_feats（扩展）\n",
    "# =====================================================\n",
    "# ratio\n",
    "deg_ratio = out_deg / (in_deg + 1e-6)\n",
    "active_span_ratio = active_span / (active_span.max() + 1e-6)\n",
    "\n",
    "# time gap\n",
    "last_edge = np.zeros(N, dtype=np.float32)\n",
    "np.maximum.at(last_edge, nodes_flat, ts_flat)\n",
    "recent_gap = global_max - last_edge\n",
    "recent_gap_norm = recent_gap / (global_max + 1e-6)\n",
    "\n",
    "deg_squared = deg ** 2\n",
    "deg_diff_abs = np.abs(deg_diff)\n",
    "span_mean_ratio = active_span / (day_mean + 1e-6)\n",
    "\n",
    "# 邻居平均度\n",
    "rows = np.concatenate([edge_index[:,0], edge_index[:,1]])\n",
    "cols = np.concatenate([edge_index[:,1], edge_index[:,0]])\n",
    "adj = coo_matrix((np.ones_like(rows), (rows, cols)), shape=(N, N))\n",
    "mean_neighbor_deg = adj.dot(deg.reshape(-1,1)).flatten() / np.maximum(adj.sum(axis=1).A1, 1)\n",
    "\n",
    "# time std\n",
    "sum_ts  = np.bincount(nodes_flat, weights=ts_flat,   minlength=N)\n",
    "sum_ts2 = np.bincount(nodes_flat, weights=ts_flat**2, minlength=N)\n",
    "cnt_ts  = np.bincount(nodes_flat, minlength=N)\n",
    "active_std = np.sqrt(np.maximum(0, sum_ts2/cnt_ts - (sum_ts/cnt_ts)**2))\n",
    "active_std[cnt_ts==0] = 0\n",
    "\n",
    "deg_rate = deg / np.maximum(active_span, 1e-6)\n",
    "\n",
    "# global skew/kurt\n",
    "deg_skew = np.full(N, skew(deg.astype(np.float64)))\n",
    "deg_kurt = np.full(N, kurtosis(deg.astype(np.float64)))\n",
    "\n",
    "more_feats = np.stack([\n",
    "    deg_ratio,\n",
    "    active_span_ratio,\n",
    "    recent_gap_norm,\n",
    "    deg_squared,\n",
    "    deg_diff_abs,\n",
    "    span_mean_ratio,\n",
    "    mean_neighbor_deg,\n",
    "    active_std,\n",
    "    deg_rate,\n",
    "    deg_skew,\n",
    "    deg_kurt\n",
    "], axis=1).astype(np.float32)\n",
    "print(\"more_feats:\", more_feats.shape)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 7) 合并 new_feats_all\n",
    "# =====================================================\n",
    "new_feats_all = np.concatenate([new_feats, more_feats], axis=1)\n",
    "print(\"new_feats_all:\", new_feats_all.shape)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 8) 打包 struct_feats\n",
    "# =====================================================\n",
    "struct_feats = np.concatenate([\n",
    "    in_deg.reshape(-1,1),\n",
    "    out_deg.reshape(-1,1),\n",
    "    recent_feats,\n",
    "    new_feats_all,\n",
    "    min_day.reshape(-1,1),\n",
    "    max_day_node.reshape(-1,1),\n",
    "], axis=1).astype(np.float32)\n",
    "\n",
    "print(\"struct_feats:\", struct_feats.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22689410-7211-4ee5-b77e-6d5b31187861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T09:28:52.773406Z",
     "iopub.status.busy": "2025-11-10T09:28:52.773205Z",
     "iopub.status.idle": "2025-11-10T09:29:00.263080Z",
     "shell.execute_reply": "2025-11-10T09:29:00.260672Z",
     "shell.execute_reply.started": "2025-11-10T09:28:52.773388Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated struct_feats: (4024623, 77)\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# ===========================\n",
    "# 已有变量\n",
    "# ===========================\n",
    "# x, y, edge_index, edge_type, edge_timestamp, N, E\n",
    "# struct_feats, in_deg, out_deg, max_day_node 已准备好\n",
    "\n",
    "global_max = max_day_node.max()\n",
    "X_recent = 30\n",
    "num_types = int(edge_type.max() + 1)\n",
    "\n",
    "# ===========================\n",
    "# 1. 构建邻接矩阵（稀疏矩阵）\n",
    "# ===========================\n",
    "rows = edge_index[:, 1]  # 入邻居\n",
    "cols = edge_index[:, 0]  # 出邻居\n",
    "data = np.ones(E, dtype=np.float32)\n",
    "A_in  = coo_matrix((data, (rows, cols)), shape=(N, N))  # 入邻居矩阵\n",
    "A_out = coo_matrix((data, (cols, rows)), shape=(N, N))  # 出邻居矩阵\n",
    "\n",
    "# ===========================\n",
    "# 2. 邻居数量\n",
    "# ===========================\n",
    "num_in_neighbors  = np.array(A_in.sum(axis=1)).flatten()\n",
    "num_out_neighbors = np.array(A_out.sum(axis=1)).flatten()\n",
    "num_all_neighbors = np.array((A_in + A_out).astype(bool).sum(axis=1)).flatten()\n",
    "ratio_in_out_neighbors = num_in_neighbors / np.maximum(num_out_neighbors, 1)\n",
    "\n",
    "# ===========================\n",
    "# 3. 邻居平均度\n",
    "# ===========================\n",
    "mean_in_deg_neighbors  = A_in.dot(in_deg) / np.maximum(num_in_neighbors, 1)\n",
    "mean_out_deg_neighbors = A_out.dot(out_deg) / np.maximum(num_out_neighbors, 1)\n",
    "\n",
    "# ===========================\n",
    "# 4. 邻居活跃时间\n",
    "# ===========================\n",
    "mean_last_active_in_neighbors  = A_in.dot(max_day_node) / np.maximum(num_in_neighbors, 1)\n",
    "mean_last_active_out_neighbors = A_out.dot(max_day_node) / np.maximum(num_out_neighbors, 1)\n",
    "\n",
    "# 最近X天活跃邻居比例\n",
    "recent_active_mask = (max_day_node > global_max - X_recent).astype(np.float32)\n",
    "recent_active_in_neighbors  = A_in.dot(recent_active_mask) / np.maximum(num_in_neighbors, 1)\n",
    "recent_active_out_neighbors = A_out.dot(recent_active_mask) / np.maximum(num_out_neighbors, 1)\n",
    "\n",
    "# ===========================\n",
    "# 5. 边类型统计\n",
    "# ===========================\n",
    "in_type_count  = np.zeros((N, num_types), dtype=np.float32)\n",
    "out_type_count = np.zeros((N, num_types), dtype=np.float32)\n",
    "np.add.at(out_type_count, (edge_index[:,0], edge_type), 1)\n",
    "np.add.at(in_type_count,  (edge_index[:,1], edge_type), 1)\n",
    "\n",
    "in_type_ratio  = in_type_count / np.maximum(in_type_count.sum(axis=1, keepdims=True), 1)\n",
    "out_type_ratio = out_type_count / np.maximum(out_type_count.sum(axis=1, keepdims=True), 1)\n",
    "\n",
    "# ===========================\n",
    "# 6. 边时间特征\n",
    "# ===========================\n",
    "last_edge_out = np.zeros(N, dtype=np.float32)\n",
    "last_edge_in  = np.zeros(N, dtype=np.float32)\n",
    "np.maximum.at(last_edge_out, edge_index[:,0], edge_timestamp)\n",
    "np.maximum.at(last_edge_in,  edge_index[:,1], edge_timestamp)\n",
    "\n",
    "gap_last_edge_out = global_max - last_edge_out\n",
    "gap_last_edge_in  = global_max - last_edge_in\n",
    "\n",
    "sum_ts_out = np.zeros(N, dtype=np.float32)\n",
    "cnt_out = np.zeros(N, dtype=np.float32)\n",
    "np.add.at(sum_ts_out, edge_index[:,0], edge_timestamp)\n",
    "np.add.at(cnt_out, edge_index[:,0], 1)\n",
    "avg_edge_time_out = sum_ts_out / np.maximum(cnt_out, 1)\n",
    "\n",
    "sum_ts_in = np.zeros(N, dtype=np.float32)\n",
    "cnt_in = np.zeros(N, dtype=np.float32)\n",
    "np.add.at(sum_ts_in, edge_index[:,1], edge_timestamp)\n",
    "np.add.at(cnt_in, edge_index[:,1], 1)\n",
    "avg_edge_time_in = sum_ts_in / np.maximum(cnt_in, 1)\n",
    "\n",
    "# ===========================\n",
    "# 7. 拼接特征\n",
    "# ===========================\n",
    "edge_feats = np.concatenate([\n",
    "    num_in_neighbors.reshape(-1,1),\n",
    "    num_out_neighbors.reshape(-1,1),\n",
    "    num_all_neighbors.reshape(-1,1),\n",
    "    ratio_in_out_neighbors.reshape(-1,1),\n",
    "    mean_in_deg_neighbors.reshape(-1,1),\n",
    "    mean_out_deg_neighbors.reshape(-1,1),\n",
    "    mean_last_active_in_neighbors.reshape(-1,1),\n",
    "    mean_last_active_out_neighbors.reshape(-1,1),\n",
    "    recent_active_in_neighbors.reshape(-1,1),\n",
    "    recent_active_out_neighbors.reshape(-1,1),\n",
    "    gap_last_edge_in.reshape(-1,1),\n",
    "    gap_last_edge_out.reshape(-1,1),\n",
    "    avg_edge_time_in.reshape(-1,1),\n",
    "    avg_edge_time_out.reshape(-1,1),\n",
    "    in_type_ratio,\n",
    "    out_type_ratio\n",
    "], axis=1)\n",
    "\n",
    "struct_feats = np.concatenate([struct_feats, edge_feats], axis=1)\n",
    "print(\"Updated struct_feats:\", struct_feats.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cc91b5d-72a6-4f3a-8673-e7f16fb9188f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T09:29:00.264588Z",
     "iopub.status.busy": "2025-11-10T09:29:00.264379Z",
     "iopub.status.idle": "2025-11-10T09:29:05.645654Z",
     "shell.execute_reply": "2025-11-10T09:29:05.644418Z",
     "shell.execute_reply.started": "2025-11-10T09:29:00.264568Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated struct_feats with 2-hop + time-weighted features: (4024623, 90)\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "\n",
    "# ===========================\n",
    "# 已有变量\n",
    "# ===========================\n",
    "# edge_index, edge_timestamp, edge_type, N, E, struct_feats, in_deg, out_deg, max_day_node\n",
    "global_max = max_day_node.max()\n",
    "X_recent = 30\n",
    "num_types = int(edge_type.max() + 1)\n",
    "\n",
    "# ===========================\n",
    "# 1. 构建稀疏邻接矩阵\n",
    "# ===========================\n",
    "rows = edge_index[:, 1]  # 入邻居\n",
    "cols = edge_index[:, 0]  # 出邻居\n",
    "data = np.ones(E, dtype=np.float32)\n",
    "A_in  = coo_matrix((data, (rows, cols)), shape=(N, N)).tocsr()   # 入邻居矩阵\n",
    "A_out = coo_matrix((data, (cols, rows)), shape=(N, N)).tocsr()   # 出邻居矩阵\n",
    "\n",
    "# ===========================\n",
    "# 2. 1-hop 邻居特征（已有，可重复使用）\n",
    "# ===========================\n",
    "num_in_neighbors  = np.array(A_in.sum(axis=1)).flatten()\n",
    "num_out_neighbors = np.array(A_out.sum(axis=1)).flatten()\n",
    "num_all_neighbors = np.array((A_in + A_out).astype(bool).sum(axis=1)).flatten()\n",
    "\n",
    "# ===========================\n",
    "# 3. 2-hop 邻居特征\n",
    "# ===========================\n",
    "# 2-hop 邻居矩阵\n",
    "A2_in  = A_in.dot(A_in)\n",
    "A2_out = A_out.dot(A_out)\n",
    "\n",
    "# 2-hop 邻居数量\n",
    "num_2hop_in  = np.array(A2_in.sum(axis=1)).flatten()\n",
    "num_2hop_out = np.array(A2_out.sum(axis=1)).flatten()\n",
    "num_2hop_all = np.array((A2_in + A2_out).astype(bool).sum(axis=1)).flatten()\n",
    "\n",
    "# 2-hop 平均邻居度\n",
    "mean_2hop_in_deg  = A2_in.dot(in_deg) / np.maximum(num_2hop_in, 1)\n",
    "mean_2hop_out_deg = A2_out.dot(out_deg) / np.maximum(num_2hop_out, 1)\n",
    "\n",
    "# 2-hop 最近 X 天活跃邻居比例\n",
    "recent_active_mask = (max_day_node > global_max - X_recent).astype(np.float32)\n",
    "recent_active_2hop_in  = A2_in.dot(recent_active_mask) / np.maximum(num_2hop_in, 1)\n",
    "recent_active_2hop_out = A2_out.dot(recent_active_mask) / np.maximum(num_2hop_out, 1)\n",
    "\n",
    "# 2-hop 邻居平均最后活跃时间\n",
    "mean_last_active_2hop_in  = A2_in.dot(max_day_node) / np.maximum(num_2hop_in, 1)\n",
    "mean_last_active_2hop_out = A2_out.dot(max_day_node) / np.maximum(num_2hop_out, 1)\n",
    "\n",
    "# ===========================\n",
    "# 4. 时间加权邻居特征\n",
    "# ===========================\n",
    "time_weight = edge_timestamp / global_max\n",
    "\n",
    "# 入/出边时间加权邻居度\n",
    "w_out = np.zeros(N, dtype=np.float32)\n",
    "w_in  = np.zeros(N, dtype=np.float32)\n",
    "np.add.at(w_out, edge_index[:,0], time_weight)\n",
    "np.add.at(w_in,  edge_index[:,1], time_weight)\n",
    "\n",
    "time_weighted_deg = w_out + w_in\n",
    "\n",
    "# 1-hop 时间加权邻居平均度\n",
    "time_weighted_deg_in  = A_in.dot(time_weighted_deg) / np.maximum(num_in_neighbors, 1)\n",
    "time_weighted_deg_out = A_out.dot(time_weighted_deg) / np.maximum(num_out_neighbors, 1)\n",
    "\n",
    "# 2-hop 时间加权邻居平均度\n",
    "time_weighted_deg_2hop_in  = A2_in.dot(time_weighted_deg) / np.maximum(num_2hop_in, 1)\n",
    "time_weighted_deg_2hop_out = A2_out.dot(time_weighted_deg) / np.maximum(num_2hop_out, 1)\n",
    "\n",
    "# ===========================\n",
    "# 5. 拼接所有 2-hop + 时间加权特征\n",
    "# ===========================\n",
    "edge_2hop_feats = np.stack([\n",
    "    num_2hop_in,\n",
    "    num_2hop_out,\n",
    "    num_2hop_all,\n",
    "    mean_2hop_in_deg,\n",
    "    mean_2hop_out_deg,\n",
    "    recent_active_2hop_in,\n",
    "    recent_active_2hop_out,\n",
    "    mean_last_active_2hop_in,\n",
    "    mean_last_active_2hop_out,\n",
    "    time_weighted_deg_in,\n",
    "    time_weighted_deg_out,\n",
    "    time_weighted_deg_2hop_in,\n",
    "    time_weighted_deg_2hop_out\n",
    "], axis=1).astype(np.float32)\n",
    "\n",
    "# ===========================\n",
    "# 6. 拼接到 struct_feats\n",
    "# ===========================\n",
    "struct_feats = np.concatenate([struct_feats, edge_2hop_feats], axis=1)\n",
    "print(\"Updated struct_feats with 2-hop + time-weighted features:\", struct_feats.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bee38cf1-c261-4a3d-93dc-c6832f6571ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T09:29:05.646918Z",
     "iopub.status.busy": "2025-11-10T09:29:05.646722Z",
     "iopub.status.idle": "2025-11-10T09:29:19.292609Z",
     "shell.execute_reply": "2025-11-10T09:29:19.291240Z",
     "shell.execute_reply.started": "2025-11-10T09:29:05.646900Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated struct_feats with 100+ features: (4024623, 140)\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# ===============================\n",
    "# 已有变量：\n",
    "# x, edge_index, edge_type, edge_timestamp, N, E\n",
    "# struct_feats, in_deg, out_deg, max_day_node 已经准备好\n",
    "# ===============================\n",
    "\n",
    "global_max = max_day_node.max()\n",
    "X_recent = 30\n",
    "num_types = int(edge_type.max() + 1)\n",
    "deg = in_deg + out_deg\n",
    "deg_diff = out_deg - in_deg\n",
    "\n",
    "# ===============================\n",
    "# 1. 邻接矩阵\n",
    "# ===============================\n",
    "rows_in, cols_in = edge_index[:,1], edge_index[:,0]  # 入邻居\n",
    "rows_out, cols_out = edge_index[:,0], edge_index[:,1]  # 出邻居\n",
    "data = np.ones(E, dtype=np.float32)\n",
    "\n",
    "A_in = coo_matrix((data, (rows_in, cols_in)), shape=(N,N))\n",
    "A_out = coo_matrix((data, (rows_out, cols_out)), shape=(N,N))\n",
    "A_all = ((A_in + A_out) > 0).astype(np.float32)\n",
    "\n",
    "# ===============================\n",
    "# 2. 邻居统计特征\n",
    "# ===============================\n",
    "num_in_neighbors  = np.array(A_in.sum(axis=1)).flatten()\n",
    "num_out_neighbors = np.array(A_out.sum(axis=1)).flatten()\n",
    "num_all_neighbors = np.array(A_all.sum(axis=1)).flatten()\n",
    "ratio_in_out_neighbors = num_in_neighbors / np.maximum(num_out_neighbors, 1)\n",
    "\n",
    "mean_in_deg_neighbors  = A_in.dot(in_deg) / np.maximum(num_in_neighbors,1)\n",
    "mean_out_deg_neighbors = A_out.dot(out_deg) / np.maximum(num_out_neighbors,1)\n",
    "\n",
    "mean_last_active_in_neighbors  = A_in.dot(max_day_node) / np.maximum(num_in_neighbors,1)\n",
    "mean_last_active_out_neighbors = A_out.dot(max_day_node) / np.maximum(num_out_neighbors,1)\n",
    "\n",
    "recent_active_mask = (max_day_node > global_max - X_recent).astype(np.float32)\n",
    "recent_active_in_neighbors  = A_in.dot(recent_active_mask) / np.maximum(num_in_neighbors,1)\n",
    "recent_active_out_neighbors = A_out.dot(recent_active_mask) / np.maximum(num_out_neighbors,1)\n",
    "\n",
    "# ===============================\n",
    "# 3. 二阶邻居统计\n",
    "# ===============================\n",
    "# 2-hop 邻居矩阵\n",
    "A2_in  = A_in.dot(A_in)\n",
    "A2_out = A_out.dot(A_out)\n",
    "num_2hop_in_neighbors  = np.array(A2_in.sum(axis=1)).flatten()\n",
    "num_2hop_out_neighbors = np.array(A2_out.sum(axis=1)).flatten()\n",
    "mean_2hop_in_deg_neighbors  = A2_in.dot(in_deg) / np.maximum(num_2hop_in_neighbors,1)\n",
    "mean_2hop_out_deg_neighbors = A2_out.dot(out_deg) / np.maximum(num_2hop_out_neighbors,1)\n",
    "\n",
    "# ===============================\n",
    "# 4. Motif/局部三元闭环特征（近似）\n",
    "# ===============================\n",
    "# 节点闭环数量 = diag(A_in.dot(A_out))\n",
    "triangles_in_out = np.array(A_in.dot(A_out).diagonal()).astype(np.float32)\n",
    "triangles_out_in = np.array(A_out.dot(A_in).diagonal()).astype(np.float32)\n",
    "\n",
    "# ===============================\n",
    "# 5. 边类型特征\n",
    "# ===============================\n",
    "in_type_count  = np.zeros((N, num_types), dtype=np.float32)\n",
    "out_type_count = np.zeros((N, num_types), dtype=np.float32)\n",
    "np.add.at(out_type_count, (edge_index[:,0], edge_type), 1)\n",
    "np.add.at(in_type_count,  (edge_index[:,1], edge_type), 1)\n",
    "in_type_ratio  = in_type_count / np.maximum(in_type_count.sum(axis=1, keepdims=True),1)\n",
    "out_type_ratio = out_type_count / np.maximum(out_type_count.sum(axis=1, keepdims=True),1)\n",
    "\n",
    "# ===============================\n",
    "# 6. 时间特征\n",
    "# ===============================\n",
    "# 最近边时间gap\n",
    "last_edge_out = np.zeros(N, dtype=np.float32)\n",
    "last_edge_in  = np.zeros(N, dtype=np.float32)\n",
    "np.maximum.at(last_edge_out, edge_index[:,0], edge_timestamp)\n",
    "np.maximum.at(last_edge_in,  edge_index[:,1], edge_timestamp)\n",
    "gap_last_edge_out = global_max - last_edge_out\n",
    "gap_last_edge_in  = global_max - last_edge_in\n",
    "\n",
    "# 平均边时间\n",
    "sum_ts_out = np.zeros(N, dtype=np.float32)\n",
    "cnt_out = np.zeros(N, dtype=np.float32)\n",
    "np.add.at(sum_ts_out, edge_index[:,0], edge_timestamp)\n",
    "np.add.at(cnt_out, edge_index[:,0], 1)\n",
    "avg_edge_time_out = sum_ts_out / np.maximum(cnt_out,1)\n",
    "\n",
    "sum_ts_in = np.zeros(N, dtype=np.float32)\n",
    "cnt_in = np.zeros(N, dtype=np.float32)\n",
    "np.add.at(sum_ts_in, edge_index[:,1], edge_timestamp)\n",
    "np.add.at(cnt_in, edge_index[:,1], 1)\n",
    "avg_edge_time_in = sum_ts_in / np.maximum(cnt_in,1)\n",
    "\n",
    "# 时间衰减加权度 (exp(-Δt/max_day))\n",
    "time_decay = np.exp(-(global_max - edge_timestamp)/global_max)\n",
    "w_out_decay = np.zeros(N, dtype=np.float32)\n",
    "w_in_decay  = np.zeros(N, dtype=np.float32)\n",
    "np.add.at(w_out_decay, edge_index[:,0], time_decay)\n",
    "np.add.at(w_in_decay, edge_index[:,1], time_decay)\n",
    "\n",
    "# ===============================\n",
    "# 7. 高阶组合特征\n",
    "# ===============================\n",
    "deg_squared = deg ** 2\n",
    "deg_diff_squared = deg_diff ** 2\n",
    "deg_log = np.log1p(deg)\n",
    "active_span = max_day_node - np.minimum(np.zeros_like(max_day_node), 0)  # placeholder\n",
    "active_span_squared = active_span ** 2\n",
    "\n",
    "# ===============================\n",
    "# 8. 拼接所有新特征\n",
    "# ===============================\n",
    "edge_feats2 = np.concatenate([\n",
    "    # 一阶邻居\n",
    "    num_in_neighbors.reshape(-1,1),\n",
    "    num_out_neighbors.reshape(-1,1),\n",
    "    num_all_neighbors.reshape(-1,1),\n",
    "    ratio_in_out_neighbors.reshape(-1,1),\n",
    "    mean_in_deg_neighbors.reshape(-1,1),\n",
    "    mean_out_deg_neighbors.reshape(-1,1),\n",
    "    mean_last_active_in_neighbors.reshape(-1,1),\n",
    "    mean_last_active_out_neighbors.reshape(-1,1),\n",
    "    recent_active_in_neighbors.reshape(-1,1),\n",
    "    recent_active_out_neighbors.reshape(-1,1),\n",
    "    # 二阶邻居\n",
    "    num_2hop_in_neighbors.reshape(-1,1),\n",
    "    num_2hop_out_neighbors.reshape(-1,1),\n",
    "    mean_2hop_in_deg_neighbors.reshape(-1,1),\n",
    "    mean_2hop_out_deg_neighbors.reshape(-1,1),\n",
    "    # Motif\n",
    "    triangles_in_out.reshape(-1,1),\n",
    "    triangles_out_in.reshape(-1,1),\n",
    "    # 边类型\n",
    "    in_type_ratio,\n",
    "    out_type_ratio,\n",
    "    # 时间特征\n",
    "    gap_last_edge_in.reshape(-1,1),\n",
    "    gap_last_edge_out.reshape(-1,1),\n",
    "    avg_edge_time_in.reshape(-1,1),\n",
    "    avg_edge_time_out.reshape(-1,1),\n",
    "    w_in_decay.reshape(-1,1),\n",
    "    w_out_decay.reshape(-1,1),\n",
    "    # 高阶组合\n",
    "    deg_squared.reshape(-1,1),\n",
    "    deg_diff_squared.reshape(-1,1),\n",
    "    deg_log.reshape(-1,1),\n",
    "    active_span_squared.reshape(-1,1),\n",
    "], axis=1)\n",
    "\n",
    "struct_feats = np.concatenate([struct_feats, edge_feats2], axis=1)\n",
    "print(\"Updated struct_feats with 100+ features:\", struct_feats.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01a67de1-d97f-4942-8375-bc1fa343a352",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T09:29:19.293966Z",
     "iopub.status.busy": "2025-11-10T09:29:19.293757Z",
     "iopub.status.idle": "2025-11-10T09:29:45.532069Z",
     "shell.execute_reply": "2025-11-10T09:29:45.530993Z",
     "shell.execute_reply.started": "2025-11-10T09:29:19.293947Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated struct_feats with 200+ features: (4024623, 198)\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "\n",
    "# ===============================\n",
    "# 已有变量：\n",
    "# x, edge_index, edge_type, edge_timestamp, N, E\n",
    "# struct_feats, in_deg, out_deg, max_day_node 已经准备好\n",
    "# ===============================\n",
    "\n",
    "global_max = max_day_node.max()\n",
    "X_recent = 30\n",
    "num_types = int(edge_type.max() + 1)\n",
    "deg = in_deg + out_deg\n",
    "deg_diff = out_deg - in_deg\n",
    "\n",
    "# ===============================\n",
    "# 1. 构建邻接矩阵\n",
    "# ===============================\n",
    "rows_in, cols_in = edge_index[:,1], edge_index[:,0]   # 入邻居\n",
    "rows_out, cols_out = edge_index[:,0], edge_index[:,1] # 出邻居\n",
    "data = np.ones(E, dtype=np.float32)\n",
    "\n",
    "A_in  = coo_matrix((data, (rows_in, cols_in)), shape=(N,N))\n",
    "A_out = coo_matrix((data, (rows_out, cols_out)), shape=(N,N))\n",
    "A_all = ((A_in + A_out) > 0).astype(np.float32)\n",
    "\n",
    "# ===============================\n",
    "# 2. 一阶邻居统计\n",
    "# ===============================\n",
    "num_in_neighbors  = np.array(A_in.sum(axis=1)).flatten()\n",
    "num_out_neighbors = np.array(A_out.sum(axis=1)).flatten()\n",
    "num_all_neighbors = np.array(A_all.sum(axis=1)).flatten()\n",
    "ratio_in_out_neighbors = num_in_neighbors / np.maximum(num_out_neighbors,1)\n",
    "\n",
    "mean_in_deg_neighbors  = A_in.dot(in_deg) / np.maximum(num_in_neighbors,1)\n",
    "mean_out_deg_neighbors = A_out.dot(out_deg) / np.maximum(num_out_neighbors,1)\n",
    "mean_neighbor_deg = A_all.dot(deg) / np.maximum(num_all_neighbors,1)\n",
    "\n",
    "mean_last_active_in_neighbors  = A_in.dot(max_day_node) / np.maximum(num_in_neighbors,1)\n",
    "mean_last_active_out_neighbors = A_out.dot(max_day_node) / np.maximum(num_out_neighbors,1)\n",
    "\n",
    "recent_active_mask = (max_day_node > global_max - X_recent).astype(np.float32)\n",
    "recent_active_in_neighbors  = A_in.dot(recent_active_mask) / np.maximum(num_in_neighbors,1)\n",
    "recent_active_out_neighbors = A_out.dot(recent_active_mask) / np.maximum(num_out_neighbors,1)\n",
    "\n",
    "# ===============================\n",
    "# 3. 二阶/三阶邻居统计\n",
    "# ===============================\n",
    "A2_in  = A_in.dot(A_in)\n",
    "A2_out = A_out.dot(A_out)\n",
    "num_2hop_in_neighbors  = np.array(A2_in.sum(axis=1)).flatten()\n",
    "num_2hop_out_neighbors = np.array(A2_out.sum(axis=1)).flatten()\n",
    "mean_2hop_in_deg_neighbors  = A2_in.dot(in_deg) / np.maximum(num_2hop_in_neighbors,1)\n",
    "mean_2hop_out_deg_neighbors = A2_out.dot(out_deg) / np.maximum(num_2hop_out_neighbors,1)\n",
    "\n",
    "A3_all = A_all.dot(A_all.dot(A_all))\n",
    "num_3hop_neighbors = np.array(A3_all.sum(axis=1)).flatten()\n",
    "mean_3hop_deg = A3_all.dot(deg) / np.maximum(num_3hop_neighbors,1)\n",
    "\n",
    "# ===============================\n",
    "# 4. Motif / 局部闭环\n",
    "# ===============================\n",
    "triangles_in_out  = np.array(A_in.dot(A_out).diagonal()).astype(np.float32)\n",
    "triangles_out_in  = np.array(A_out.dot(A_in).diagonal()).astype(np.float32)\n",
    "triangles_all = np.array(A_all.dot(A_all).diagonal()).astype(np.float32)\n",
    "\n",
    "# ===============================\n",
    "# 5. 边类型统计\n",
    "# ===============================\n",
    "in_type_count  = np.zeros((N,num_types), dtype=np.float32)\n",
    "out_type_count = np.zeros((N,num_types), dtype=np.float32)\n",
    "np.add.at(out_type_count, (edge_index[:,0], edge_type), 1)\n",
    "np.add.at(in_type_count,  (edge_index[:,1], edge_type), 1)\n",
    "\n",
    "in_type_ratio  = in_type_count / np.maximum(in_type_count.sum(axis=1, keepdims=True),1)\n",
    "out_type_ratio = out_type_count / np.maximum(out_type_count.sum(axis=1, keepdims=True),1)\n",
    "\n",
    "# 类型熵 & 方差\n",
    "type_entropy_in  = entropy(in_type_ratio.T + 1e-6)\n",
    "type_entropy_out = entropy(out_type_ratio.T + 1e-6)\n",
    "type_var_in = in_type_ratio.var(axis=1)\n",
    "type_var_out = out_type_ratio.var(axis=1)\n",
    "\n",
    "# ===============================\n",
    "# 6. 时间特征\n",
    "# ===============================\n",
    "last_edge_out = np.zeros(N, dtype=np.float32)\n",
    "last_edge_in  = np.zeros(N, dtype=np.float32)\n",
    "np.maximum.at(last_edge_out, edge_index[:,0], edge_timestamp)\n",
    "np.maximum.at(last_edge_in,  edge_index[:,1], edge_timestamp)\n",
    "\n",
    "gap_last_edge_out = global_max - last_edge_out\n",
    "gap_last_edge_in  = global_max - last_edge_in\n",
    "\n",
    "sum_ts_out = np.zeros(N, dtype=np.float32)\n",
    "cnt_out = np.zeros(N, dtype=np.float32)\n",
    "np.add.at(sum_ts_out, edge_index[:,0], edge_timestamp)\n",
    "np.add.at(cnt_out, edge_index[:,0], 1)\n",
    "avg_edge_time_out = sum_ts_out / np.maximum(cnt_out,1)\n",
    "\n",
    "sum_ts_in = np.zeros(N, dtype=np.float32)\n",
    "cnt_in = np.zeros(N, dtype=np.float32)\n",
    "np.add.at(sum_ts_in, edge_index[:,1], edge_timestamp)\n",
    "np.add.at(cnt_in, edge_index[:,1], 1)\n",
    "avg_edge_time_in = sum_ts_in / np.maximum(cnt_in,1)\n",
    "\n",
    "time_decay = np.exp(-(global_max - edge_timestamp)/global_max)\n",
    "w_out_decay = np.zeros(N, dtype=np.float32)\n",
    "w_in_decay  = np.zeros(N, dtype=np.float32)\n",
    "np.add.at(w_out_decay, edge_index[:,0], time_decay)\n",
    "np.add.at(w_in_decay,  edge_index[:,1], time_decay)\n",
    "\n",
    "# ===============================\n",
    "# 7. 节点高阶组合特征\n",
    "# ===============================\n",
    "deg_squared = deg ** 2\n",
    "deg_diff_squared = deg_diff ** 2\n",
    "deg_log = np.log1p(deg)\n",
    "active_span = max_day_node - np.minimum(np.zeros_like(max_day_node),0)\n",
    "active_span_squared = active_span ** 2\n",
    "\n",
    "# 节点度z-score\n",
    "deg_z = (deg - deg.mean()) / (deg.std()+1e-6)\n",
    "neighbor_deg_z = (mean_neighbor_deg - mean_neighbor_deg.mean()) / (mean_neighbor_deg.std()+1e-6)\n",
    "active_z = (max_day_node - max_day_node.mean()) / (max_day_node.std()+1e-6)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 8. 拼接所有特征到节点矩阵\n",
    "# ===============================\n",
    "edge_feats3 = np.concatenate([\n",
    "    # 一阶邻居\n",
    "    num_in_neighbors.reshape(-1,1), num_out_neighbors.reshape(-1,1), num_all_neighbors.reshape(-1,1),\n",
    "    ratio_in_out_neighbors.reshape(-1,1), mean_in_deg_neighbors.reshape(-1,1), mean_out_deg_neighbors.reshape(-1,1),\n",
    "    mean_last_active_in_neighbors.reshape(-1,1), mean_last_active_out_neighbors.reshape(-1,1),\n",
    "    recent_active_in_neighbors.reshape(-1,1), recent_active_out_neighbors.reshape(-1,1),\n",
    "    # 二阶/三阶邻居\n",
    "    num_2hop_in_neighbors.reshape(-1,1), num_2hop_out_neighbors.reshape(-1,1),\n",
    "    mean_2hop_in_deg_neighbors.reshape(-1,1), mean_2hop_out_deg_neighbors.reshape(-1,1),\n",
    "    num_3hop_neighbors.reshape(-1,1), mean_3hop_deg.reshape(-1,1),\n",
    "    # Motif\n",
    "    triangles_in_out.reshape(-1,1), triangles_out_in.reshape(-1,1), triangles_all.reshape(-1,1),\n",
    "    # 边类型\n",
    "    in_type_ratio, out_type_ratio,\n",
    "    type_var_in.reshape(-1,1), type_var_out.reshape(-1,1),\n",
    "    # 时间\n",
    "    gap_last_edge_in.reshape(-1,1), gap_last_edge_out.reshape(-1,1),\n",
    "    avg_edge_time_in.reshape(-1,1), avg_edge_time_out.reshape(-1,1),\n",
    "    w_in_decay.reshape(-1,1), w_out_decay.reshape(-1,1),\n",
    "    # 高阶组合\n",
    "    deg_squared.reshape(-1,1), deg_diff_squared.reshape(-1,1), deg_log.reshape(-1,1),\n",
    "    active_span_squared.reshape(-1,1), deg_z.reshape(-1,1), neighbor_deg_z.reshape(-1,1),\n",
    "    # active_z.reshape(-1,1), neighbor_active_skew.reshape(-1,1), neighbor_active_kurt.reshape(-1,1),\n",
    "    active_z.reshape(-1,1),\n",
    "], axis=1)\n",
    "\n",
    "struct_feats = np.concatenate([struct_feats, edge_feats3], axis=1)\n",
    "print(\"Updated struct_feats with 200+ features:\", struct_feats.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9da525a-a2d8-4ca0-8d87-d3b41be6c3c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T09:33:34.668093Z",
     "iopub.status.busy": "2025-11-10T09:33:34.667814Z",
     "iopub.status.idle": "2025-11-10T09:33:37.355131Z",
     "shell.execute_reply": "2025-11-10T09:33:37.354217Z",
     "shell.execute_reply.started": "2025-11-10T09:33:34.668072Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final X: (4024623, 215)\r\n",
      "Train: 744612 Val: 82735 Test: 354578\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================================================\n",
    "# 9) 最终 X\n",
    "# =====================================================\n",
    "X = np.concatenate([x, struct_feats], axis=1).astype(np.float32)\n",
    "D = X.shape[1]\n",
    "print(\"Final X:\", X.shape)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 10) 二分类 (只关心 y==1)\n",
    "# =====================================================\n",
    "y_bin = np.zeros(N, dtype=np.int64)\n",
    "mask_label = (y != -100)\n",
    "y_bin[mask_label] = (y[mask_label] == 1).astype(np.int64)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 11) train/val split\n",
    "# =====================================================\n",
    "train_idx = train_mask[y[train_mask] != -100]\n",
    "train_idx_local, val_idx_local = train_test_split(\n",
    "    train_idx,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=y_bin[train_idx]\n",
    ")\n",
    "\n",
    "print(\"Train:\", len(train_idx_local),\n",
    "      \"Val:\", len(val_idx_local),\n",
    "      \"Test:\", len(test_mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d0a7cf0-1bf2-451e-9ec3-ff45f922813c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T09:33:40.976806Z",
     "iopub.status.busy": "2025-11-10T09:33:40.976436Z",
     "iopub.status.idle": "2025-11-10T09:33:41.191593Z",
     "shell.execute_reply": "2025-11-10T09:33:41.190718Z",
     "shell.execute_reply.started": "2025-11-10T09:33:40.976777Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始类数量：pos = 8791 neg = 735821\r\n",
      "共生成 9 个训练子集，每个子集大小约 = 17582\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# 原始训练数据\n",
    "X_train = X[train_idx_local]\n",
    "y_train = y_bin[train_idx_local]\n",
    "\n",
    "X_val = X[val_idx_local]\n",
    "y_val = y_bin[val_idx_local]\n",
    "\n",
    "# 找到正负样本索引\n",
    "pos_idx = np.where(y_train == 1)[0]\n",
    "neg_idx = np.where(y_train == 0)[0]\n",
    "\n",
    "print(\"原始类数量：pos =\", len(pos_idx), \"neg =\", len(neg_idx))\n",
    "\n",
    "# --- 1. 切割负样本 ---\n",
    "chunk_size =int( len(pos_idx))  # 每块负样本数量\n",
    "neg_chunks = [neg_idx[i:i+chunk_size] for i in range(0, len(neg_idx), chunk_size)]\n",
    "\n",
    "neg_chunks = neg_chunks[:9]\n",
    "\n",
    "\n",
    "# --- 2. 为每块生成对应的训练索引（正样本随机取 80%） ---\n",
    "train_chunks_idx = []\n",
    "n_pos_sample = int(len(pos_idx))\n",
    "for neg_chunk in neg_chunks:\n",
    "    pos_sample_idx = np.random.choice(pos_idx, size=n_pos_sample, replace=False)\n",
    "    train_idx_chunk = np.concatenate([pos_sample_idx, neg_chunk])\n",
    "    np.random.shuffle(train_idx_chunk)\n",
    "    train_chunks_idx.append(train_idx_chunk)\n",
    "\n",
    "print(f\"共生成 {len(train_chunks_idx)} 个训练子集，每个子集大小约 = {len(train_chunks_idx[0])}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37132efe-2bd9-4d24-93c7-e3c00e020b99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T09:33:44.011006Z",
     "iopub.status.busy": "2025-11-10T09:33:44.010730Z",
     "iopub.status.idle": "2025-11-10T09:33:55.808487Z",
     "shell.execute_reply": "2025-11-10T09:33:55.807578Z",
     "shell.execute_reply.started": "2025-11-10T09:33:44.010987Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "==== Train model: HistGB on 3 chunks ====\r\n",
      "   >> HistGB chunk 1/3\r\n",
      "              precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0       1.00      0.70      0.82     81758\r\n",
      "           1       0.03      0.86      0.06       977\r\n",
      "\r\n",
      "    accuracy                           0.70     82735\r\n",
      "   macro avg       0.52      0.78      0.44     82735\r\n",
      "weighted avg       0.99      0.70      0.81     82735\r\n",
      "\r\n",
      "AUC = 0.8288667058282673\r\n",
      "   >> HistGB chunk 2/3\r\n",
      "              precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0       1.00      0.69      0.82     81758\r\n",
      "           1       0.03      0.85      0.06       977\r\n",
      "\r\n",
      "    accuracy                           0.70     82735\r\n",
      "   macro avg       0.51      0.77      0.44     82735\r\n",
      "weighted avg       0.99      0.70      0.81     82735\r\n",
      "\r\n",
      "AUC = 0.830862967206587\r\n",
      "   >> HistGB chunk 3/3\r\n",
      "              precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0       1.00      0.70      0.82     81758\r\n",
      "           1       0.03      0.85      0.06       977\r\n",
      "\r\n",
      "    accuracy                           0.70     82735\r\n",
      "   macro avg       0.51      0.77      0.44     82735\r\n",
      "weighted avg       0.99      0.70      0.81     82735\r\n",
      "\r\n",
      "AUC = 0.8268458881183234\r\n",
      "\r\n",
      "==== Train model: XGBoost on 3 chunks ====\r\n",
      "   >> XGBoost chunk 1/3\r\n",
      "              precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0       1.00      0.69      0.82     81758\r\n",
      "           1       0.03      0.84      0.06       977\r\n",
      "\r\n",
      "    accuracy                           0.70     82735\r\n",
      "   macro avg       0.51      0.77      0.44     82735\r\n",
      "weighted avg       0.99      0.70      0.81     82735\r\n",
      "\r\n",
      "AUC = 0.8166905523886393\r\n",
      "   >> XGBoost chunk 2/3\r\n",
      "              precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0       1.00      0.69      0.82     81758\r\n",
      "           1       0.03      0.83      0.06       977\r\n",
      "\r\n",
      "    accuracy                           0.69     82735\r\n",
      "   macro avg       0.51      0.76      0.44     82735\r\n",
      "weighted avg       0.99      0.69      0.81     82735\r\n",
      "\r\n",
      "AUC = 0.8128191587610469\r\n",
      "   >> XGBoost chunk 3/3\r\n",
      "              precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0       1.00      0.70      0.82     81758\r\n",
      "           1       0.03      0.84      0.06       977\r\n",
      "\r\n",
      "    accuracy                           0.70     82735\r\n",
      "   macro avg       0.51      0.77      0.44     82735\r\n",
      "weighted avg       0.99      0.70      0.81     82735\r\n",
      "\r\n",
      "AUC = 0.8151603918426858\r\n",
      "\r\n",
      "==== Train model: LightGBM on 3 chunks ====\r\n",
      "[LightGBM] [Info] Number of positive: 8791, number of negative: 8791\r\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006599 seconds.\r\n",
      "You can set `force_row_wise=true` to remove the overhead.\r\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\r\n",
      "[LightGBM] [Info] Total Bins 17906\r\n",
      "[LightGBM] [Info] Number of data points in the train set: 17582, number of used features: 203\r\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\r\n",
      "  warnings.warn(\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   >> LightGBM chunk 1/3\r\n",
      "              precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0       1.00      0.70      0.82     81758\r\n",
      "           1       0.03      0.86      0.06       977\r\n",
      "\r\n",
      "    accuracy                           0.70     82735\r\n",
      "   macro avg       0.52      0.78      0.44     82735\r\n",
      "weighted avg       0.99      0.70      0.81     82735\r\n",
      "\r\n",
      "AUC = 0.8304146373213226\r\n",
      "[LightGBM] [Info] Number of positive: 8791, number of negative: 8791\r\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006504 seconds.\r\n",
      "You can set `force_row_wise=true` to remove the overhead.\r\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\r\n",
      "[LightGBM] [Info] Total Bins 18006\r\n",
      "[LightGBM] [Info] Number of data points in the train set: 17582, number of used features: 206\r\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\r\n",
      "  warnings.warn(\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   >> LightGBM chunk 2/3\r\n",
      "              precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0       1.00      0.69      0.82     81758\r\n",
      "           1       0.03      0.86      0.06       977\r\n",
      "\r\n",
      "    accuracy                           0.69     82735\r\n",
      "   macro avg       0.51      0.77      0.44     82735\r\n",
      "weighted avg       0.99      0.69      0.81     82735\r\n",
      "\r\n",
      "AUC = 0.8319476584952528\r\n",
      "[LightGBM] [Info] Number of positive: 8791, number of negative: 8791\r\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007280 seconds.\r\n",
      "You can set `force_row_wise=true` to remove the overhead.\r\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\r\n",
      "[LightGBM] [Info] Total Bins 17937\r\n",
      "[LightGBM] [Info] Number of data points in the train set: 17582, number of used features: 203\r\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\r\n",
      "  warnings.warn(\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   >> LightGBM chunk 3/3\r\n",
      "              precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0       1.00      0.70      0.82     81758\r\n",
      "           1       0.03      0.86      0.06       977\r\n",
      "\r\n",
      "    accuracy                           0.70     82735\r\n",
      "   macro avg       0.52      0.78      0.44     82735\r\n",
      "weighted avg       0.99      0.70      0.81     82735\r\n",
      "\r\n",
      "AUC = 0.8271960177154121\r\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "# ====== 6 个不同模型（带不同参数）直接写在一起 ======\n",
    "models = [\n",
    "    {\"name\": \"HistGB\", \"cls\": HistGradientBoostingClassifier},\n",
    "    {\"name\": \"XGBoost\", \"cls\": XGBClassifier},\n",
    "    {\"name\": \"LightGBM\", \"cls\": LGBMClassifier},\n",
    "]\n",
    "\n",
    "trained_models = []\n",
    "val_probs_all = []\n",
    "\n",
    "n_chunks = len(train_chunks_idx)\n",
    "part_size = n_chunks // len(models)\n",
    "\n",
    "# 分配 chunk\n",
    "model_chunks = [train_chunks_idx[i*part_size : (i+1)*part_size if i<len(models)-1 else n_chunks] for i in range(len(models))]\n",
    "\n",
    "\n",
    "\n",
    "for model_idx, model_info in enumerate(models):\n",
    "    name = model_info[\"name\"]\n",
    "    cls = model_info[\"cls\"]\n",
    "    chunks = model_chunks[model_idx]\n",
    "\n",
    "    print(f\"\\n==== Train model: {name} on {len(chunks)} chunks ====\")\n",
    "    for i, train_idx_chunk in enumerate(chunks):\n",
    "        X_train_chunk = X_train[train_idx_chunk]\n",
    "        y_train_chunk = y_train[train_idx_chunk]\n",
    "\n",
    "        clf = cls() if callable(cls) else cls\n",
    "        clf.fit(X_train_chunk, y_train_chunk)\n",
    "        trained_models.append(clf)\n",
    "\n",
    "        # validation\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            val_prob = clf.predict_proba(X_val)[:,1]\n",
    "        else:\n",
    "            val_prob = clf.decision_function(X_val)\n",
    "            val_prob = (val_prob - val_prob.min()) / (val_prob.max() - val_prob.min())\n",
    "        val_probs_all.append(val_prob)\n",
    "\n",
    "        val_pred = (val_prob > 0.5).astype(int)\n",
    "        print(f\"   >> {name} chunk {i+1}/{len(chunks)}\")\n",
    "        print(classification_report(y_val, val_pred))\n",
    "        print(\"AUC =\", roc_auc_score(y_val, val_prob))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3870e1fe-cb85-4b22-a9a9-278b2fcdb855",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T09:33:55.829624Z",
     "iopub.status.busy": "2025-11-10T09:33:55.829416Z",
     "iopub.status.idle": "2025-11-10T09:33:56.050578Z",
     "shell.execute_reply": "2025-11-10T09:33:56.049825Z",
     "shell.execute_reply.started": "2025-11-10T09:33:55.829607Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights 1.0\r\n",
      "weights [0.111695   0.11196401 0.11142268 0.11005419 0.10953249 0.10984799\r\n",
      " 0.11190359 0.11211018 0.11146987]\r\n",
      "\r\n",
      "==== Ensemble result (weighted by AUC) ====\r\n",
      "              precision    recall  f1-score   support\r\n",
      "\r\n",
      "           0       1.00      0.70      0.82     81758\r\n",
      "           1       0.03      0.86      0.06       977\r\n",
      "\r\n",
      "    accuracy                           0.70     82735\r\n",
      "   macro avg       0.52      0.78      0.44     82735\r\n",
      "weighted avg       0.99      0.70      0.81     82735\r\n",
      "\r\n",
      "AUC = 0.8323805522566875\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "# ====== 计算每个子模型的 AUC 并作为权重 ======\n",
    "auc_list = []\n",
    "for val_prob in val_probs_all:\n",
    "    auc = roc_auc_score(y_val, val_prob)\n",
    "    auc_list.append(auc)\n",
    "\n",
    "auc_array = np.array(auc_list)\n",
    "# 权重 = AUC / sum(AUC)\n",
    "weights = auc_array / auc_array.sum()\n",
    "\n",
    "print(\"weights\",sum(weights))\n",
    "print(\"weights\",weights[:20])\n",
    "# ====== 加权融合 ======\n",
    "val_probs_all = np.array(val_probs_all)  # shape: (num_models*num_chunks, num_val_samples)\n",
    "ensemble_prob = np.average(val_probs_all, axis=0, weights=weights)\n",
    "ensemble_pred = (ensemble_prob > 0.5).astype(int)\n",
    "\n",
    "# ====== 输出结果 ======\n",
    "print(\"\\n==== Ensemble result (weighted by AUC) ====\")\n",
    "print(classification_report(y_val, ensemble_pred))\n",
    "print(\"AUC =\", roc_auc_score(y_val, ensemble_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "343a1935-d5c5-402c-a6e6-6c23717137f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T09:33:58.164483Z",
     "iopub.status.busy": "2025-11-10T09:33:58.164184Z",
     "iopub.status.idle": "2025-11-10T09:34:11.109056Z",
     "shell.execute_reply": "2025-11-10T09:34:11.107763Z",
     "shell.execute_reply.started": "2025-11-10T09:33:58.164462Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "==== Doing inference on test_mask ====\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\r\n",
      "  warnings.warn(\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission to submission.npy, shape = (354578, 2)\r\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "#   Test inference — 多模型 + AUC weighted ensemble\n",
    "# =============================================================\n",
    "print(\"\\n==== Doing inference on test_mask ====\")\n",
    "\n",
    "# 拿到测试特征\n",
    "test_feats = X[test_mask]    # (N_test, D)\n",
    "\n",
    "# 为所有模型生成预测\n",
    "test_probs_all = []\n",
    "\n",
    "for clf in trained_models:\n",
    "    # 预测概率\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        prob = clf.predict_proba(test_feats)[:, 1]    # positive prob\n",
    "    else:\n",
    "        prob = clf.decision_function(test_feats)\n",
    "        # normalize → [0,1]\n",
    "        prob = (prob - prob.min()) / (prob.max() - prob.min() + 1e-9)\n",
    "\n",
    "    test_probs_all.append(prob)\n",
    "\n",
    "test_probs_all = np.array(test_probs_all)   # (num_models, N_test)\n",
    "\n",
    "# ---------------------------\n",
    "#   AUC 加权融合\n",
    "# ---------------------------\n",
    "# weights shape = (num_models,)\n",
    "test_ensemble_prob = np.average(test_probs_all, axis=0, weights=weights)\n",
    "\n",
    "# 生成提交格式\n",
    "submission = np.vstack([\n",
    "    1.0 - test_ensemble_prob,\n",
    "    test_ensemble_prob\n",
    "]).T.astype(np.float32)      # (N_test, 2)\n",
    "\n",
    "OUTPUT_NPY = \"submission.npy\"\n",
    "np.save(OUTPUT_NPY, submission)\n",
    "\n",
    "print(f\"Saved submission to {OUTPUT_NPY}, shape = {submission.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f3303-0526-4ceb-9994-87715340438b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
